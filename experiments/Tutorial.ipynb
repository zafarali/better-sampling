{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will introduce to how experiments can be peformed on various Samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roboschool not installed. \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from rvi_sampling import utils\n",
    "from rvi_sampling.samplers import ISSampler, ABCSampler, MCSampler\n",
    "from rvi_sampling.distributions.proposal_distributions import FunnelProposal, SimonsSoftProposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIMENSIONS = 1    # Set dimension of the random walk\n",
    "OUTPUT_SIZE = 2   # The output dimension of sampler networks (action, action probabilities)\n",
    "BIASED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Command line parsers can be created using the `utils.parsers.create_parser` function. This adds basic command line arguments for rvi sampling and basic experimental arguments\n",
    "```\n",
    "parser = utils.parsers.create_parser('1D random walk', 'random_walk')\n",
    "```\n",
    "\n",
    "\n",
    "additional required arguments can be added using the `parser.add_argument` function\n",
    "```\n",
    "parser.add_argument('-cycles', '--cycles', type=int, default=15,\n",
    "                    help='number of train-test cycles.')\n",
    "```\n",
    "\n",
    "The `parser.parse_args` function execute the parser on the command line arguments and we get the parameters in the variable assigned to it.\n",
    "```\n",
    "args = parser.parse_args()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the purpose of tutorial, the args variable is set manually\n",
    "\n",
    "### rvi arguments\n",
    "\n",
    "class Arguments():\n",
    "    def __init__(\n",
    "        entropy = 0,  # Rvi environment\n",
    "        baseline_decay = 0.99,\n",
    "        learning_rate = 0.001,\n",
    "        baseline_learning_rate = 0.001,\n",
    "        only_rvi = False,\n",
    "        no_train = False,\n",
    "        baseline_type = 'moving_average',\n",
    "        notime = True,\n",
    "        gamma = 1,\n",
    "        rewardclip = -10,\n",
    "        gae = False,\n",
    "        lam = 1.0,\n",
    "        n_agents = 1,\n",
    "        plot_posterior = False,\n",
    "        neural_network = [16, 16],\n",
    "        pretrained = None,\n",
    "        samples = 1000, # experimental arguments\n",
    "        sampler_seed = 0,\n",
    "        n_cpus = 3,\n",
    "        no_tensorboard = False,\n",
    "        name = 'results',\n",
    "        IS_proposal = 'funnel',\n",
    "        softness_coefficient = 1.0,\n",
    "        override_endpoint = False,\n",
    "        outfolder = './',\n",
    "        profile_performance = False\n",
    "    ):\n",
    "        entropy = entropy\n",
    "        baseline_decay = baseline_decay\n",
    "        learning_rate = learning_rate\n",
    "        baseline_learning_rate = baseline_learning_rate\n",
    "        only_rvi = only_rvi\n",
    "        no_train = no_train\n",
    "        baseline_type = baseline_type\n",
    "        notime = notime\n",
    "        gamma = gamma\n",
    "        rewardclip = rewardclip\n",
    "        gae = gae\n",
    "        lam = lam\n",
    "        n_agents = n_agents,\n",
    "        plot_posterior = plot_posterior,\n",
    "        neural_network = neural_network,\n",
    "        pretrained = pretrained,\n",
    "        samples = samples, # experimental arguments\n",
    "        sampler_seed = sampler_seed,\n",
    "        n_cpus = n_cpus,\n",
    "        no_tensorboard = no_tensorboard,\n",
    "        name = name,\n",
    "        IS_proposal = IS_proposal,\n",
    "        softness_coefficient = softness_coefficient,\n",
    "        override_endpoint = override_endpoint,\n",
    "        outfolder = outfolder,\n",
    "        profile_performance = profile_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This sets the global seed for the random number generators\n",
    "utils.common.set_global_seeds(args.sampler_seed)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Create the folder name for where the results are to be stored\n",
    "folder_name = utils.io.create_folder_name(args.outfolder, args.name+'_'+str(args.sampler_seed)+'_'+str(args.rw_seed)+'_'+str(args.method))\n",
    "\n",
    "# Training results are stored in separate train folder\n",
    "train_folder_name = os.path.join(folder_name, 'training_results')\n",
    "\n",
    "train_folder_to_save_in = os.path.join(train_folder_name, '0')\n",
    "utils.io.create_folder(train_folder_to_save_in)\n",
    "\n",
    "# This tracks the training kl divergence results cumulatively\n",
    "kl_train_cumulative_track = os.path.join(folder_name, 'kl_training_cumulative.txt')\n",
    "kl_train_track = os.path.join(folder_name, 'kl_training.txt')\n",
    "\n",
    "# This trackes the proposal success rates cumulatively\n",
    "prop_train_cumulative_track = os.path.join(folder_name, 'prop_training_cumulative.txt')\n",
    "prop_train_track = os.path.join(folder_name, 'prop_training.txt')\n",
    "\n",
    "# These functions create the folders required for saving results\n",
    "utils.io.create_folder(folder_name)\n",
    "utils.io.create_folder(train_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function creates the random walk with the given parameters\n",
    "# The n_agents parameter shows how many agents are interacting with the random walk\n",
    "# Different stochastic processes can be implemented similar to random walk\n",
    "rw, analytic = utils.stochastic_processes.create_rw(args, biased=BIASED, n_agents=args.n_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This argument decides if we want to override the endpoint of the random walk process\n",
    "if args.override_endpoint:\n",
    "    rw.xT = np.array([ args.endpoint ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.io.touch(os.path.join(folder_name, 'start={}'.format(rw.x0)))\n",
    "utils.io.touch(os.path.join(folder_name, 'end={}'.format(rw.xT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this argument sets where the ISproposal should push toward\n",
    "push_toward = [-args.rw_width, args.rw_width]\n",
    "\n",
    "# The soft proposal makes IS proposal softer such that the push towards is lighter\n",
    "# the intensity of softness is given by the softness coefficient\n",
    "if args.IS_proposal == 'soft':\n",
    "    proposal = SimonsSoftProposal(push_toward, softness_coeff=args.softness_coefficient)\n",
    "else:\n",
    "    proposal = FunnelProposal(push_toward)\n",
    "\n",
    "if args.method == 'ISSampler':\n",
    "    sampler = ISSampler(proposal, seed=args.sampler_seed)\n",
    "elif args.method == 'MCSampler':\n",
    "    sampler = MCSampler(seed=args.sampler_seed)\n",
    "elif args.method == 'ABCSampler':\n",
    "    sampler = ABCSampler('slacked',seed=args.sampler_seed)\n",
    "else:\n",
    "    raise ValueError('Unknown method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kl_function(estimated_distribution):\n",
    "    return analytic.kl_divergence(estimated_distribution, rw.xT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler.set_diagnostic(utils.diagnostics.create_diagnostic(sampler._name, args, folder_name, kl_function))\n",
    "\n",
    "print('True Starting Position is:{}'.format(rw.x0))\n",
    "print('True Ending Position is: {}'.format(rw.xT))\n",
    "print('Analytic Starting Position: {}'.format(analytic.expectation(rw.xT[0])))\n",
    "\n",
    "train_results = None\n",
    "\n",
    "utils.io.touch(kl_train_track)\n",
    "utils.io.touch(kl_train_cumulative_track)\n",
    "utils.io.touch(prop_train_track)\n",
    "utils.io.touch(prop_train_cumulative_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, args.cycles+1):\n",
    "    train_results_new = sampler.solve(rw, args.samples)\n",
    "\n",
    "    # technically doing this saving doesn't take too long so doesn't need to be run\n",
    "    # in a background thread. This is good because it saves time of having to copy\n",
    "    # the policy for saving etc.\n",
    "    if train_results is None:\n",
    "        train_results = train_results_new\n",
    "    else:\n",
    "        # augment the old Results object.\n",
    "        train_results._all_trajectories.extend(train_results_new.all_trajectories())\n",
    "        train_results._trajectories.extend(train_results_new.trajectories())\n",
    "        train_results._posterior_particles = np.hstack([train_results.posterior(),\n",
    "                                                        train_results_new.posterior()])\n",
    "\n",
    "        train_results._posterior_weights = np.hstack([train_results.posterior_weights(),\n",
    "                                                      train_results_new.posterior_weights()])\n",
    "\n",
    "\n",
    "    steps_so_far = str(i * args.samples)\n",
    "\n",
    "\n",
    "    train_folder_to_save_in = os.path.join(train_folder_name, str(i))\n",
    "    utils.io.create_folder(train_folder_to_save_in)\n",
    "    print('Training Phase:')\n",
    "    kld = utils.analysis.analyze_samplers_rw([train_results], args, None, rw,\n",
    "                                       policy=None, analytic=analytic) # don't save these things again\n",
    "\n",
    "    utils.io.stash(kl_train_cumulative_track, steps_so_far + ', ' + str(kld[0]))\n",
    "    utils.io.stash(prop_train_cumulative_track, steps_so_far + ', ' + str(train_results.prop_success()))\n",
    "\n",
    "\n",
    "    kld = utils.analysis.analyze_samplers_rw([train_results_new], args, train_folder_to_save_in, rw,\n",
    "                                       policy=None, analytic=analytic) # don't save these things again\n",
    "    utils.io.stash(kl_train_track, steps_so_far + ', ' + str(kld[0]))\n",
    "    utils.io.stash(prop_train_track, steps_so_far + ', ' + str(train_results_new.prop_success()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at how different samplers behave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte Carlo Sampler takes a random direction at each step of the random walk. For random walks with endpoints near the start region MC Samplers work well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For endpoint=0, the trajectories obtained from the sampler will be\n",
    "\n",
    "![alt text](img/successful_trajectories_mc_end0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For endpoint=8, the trajectories will be\n",
    "\n",
    "![no_img](img/successful_trajectories_mc_end8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance Sampling Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "endpoint=0\n",
    "\n",
    "![no_img](img/successful_trajectories_is_end0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "endpoint=8\n",
    "\n",
    "![no_img](img/successful_trajectories_is_end8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance Sampling with Soft Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "endpoint=0\n",
    "\n",
    "![no_img](img/successful_trajectories_issoft_end0.jpg)\n",
    "\n",
    "endpoint=8\n",
    "\n",
    "![no_img](img/successful_trajectories_issoft_end8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RVI Sampler\n",
    "\n",
    "### Initial Stages of Training\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we look at how different samplers(MCSampler, ISSampler with handmade proposal, ISSampler with a soft proposal) behave in different conditions. The endpoint of the process is changed to reflect different difficulty conditions. Endpoints farther from the starting position requires low probability trajectories to be successful. Monte Carlo sampler performs poorly in these adverse conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparisons between samplers on random walk of varying difficulties\n",
    "\n",
    "![no_img](img/difficulty_comparissons.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rvi)",
   "language": "python",
   "name": "rvi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
